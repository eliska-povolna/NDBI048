{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second report of lyrics dataset\n",
    "\n",
    "The lyrics dataset contains popular songs with lyrics. There are six columns: id, song name, year of publishing, interpret name, assigned genre and the lyrics. Some rows are music composition without lyrics. There are hyphens instead of spaces\n",
    "in names of songs and interprets.\n",
    "\n",
    "After preprocessing the data to contain useful features, I will use analytical approach to find some dependencies or correlations to be able create a meaningful model based on my findings in the next report.\n",
    "\n",
    "This first report will be exploratory and it will contain:\n",
    "1. [Input data description and overview](#input-data)\n",
    "2. [Data processing steps and methods](#data-processing)\n",
    "3. [Data exploration](#data-exploration)\n",
    "4. [Next steps](#next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Featurization\n",
    "\n",
    "Since words cannot be used for modelling as they are, we will need to create some features to be able to analyze them further. We will come back again to featurization in modelling stage since right now I cannot be sure which features we will need. But for exploration, I will create the following features:\n",
    "- Word count: the total number of words in the lyrics\n",
    "- Unique word count: the number of unique words in the lyrics\n",
    "- Average word length: the average length of the words in the lyrics\n",
    "- TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Based on the results, in my next report, I would like to dedicate space to the following topics:\n",
    "- creating a representative sample to be able to process data faster\n",
    "- separating songs based on their language (either by using a library or by unsupervised clustering): this could significantly improve performance of any other model\n",
    "- prediction of song genre/interpreter/year according to lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 13: Connection with Machine Learning Model\n",
    "# # If you have a machine learning model from a previous project that you think might be relevant,\n",
    "# # you can apply it to your current dataset and discuss the results.\n",
    "\n",
    "# # Step 14: Language Analysis\n",
    "# # If your dataset contains songs in different languages, you might want to perform some analysis based on language.\n",
    "# # This could involve using a language detection library to add a new 'language' feature to your dataset,\n",
    "# # and then performing some of the above analyses (e.g., word count, unique word count) separately for each language.\n",
    "\n",
    "# from langdetect import detect\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Vectorize the lyrics\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(df['lyrics'].dropna())\n",
    "\n",
    "# # Fit DBSCAN\n",
    "# dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust these parameters as needed\n",
    "# dbscan.fit(X)\n",
    "\n",
    "# # Predict the clusters\n",
    "# df['cluster'] = dbscan.labels_\n",
    "\n",
    "# # Detect language of the first song's lyrics\n",
    "# lang = detect(df['lyrics'].iloc[0])\n",
    "# print(lang)\n",
    "\n",
    "# # from sklearn.cluster import KMeans\n",
    "# # from sklearn.metrics import silhouette_score\n",
    "\n",
    "# # scores = []\n",
    "# # for k in range(2, 10):\n",
    "# #     kmeans = KMeans(n_clusters=k)\n",
    "# #     kmeans.fit(X)\n",
    "# #     score = silhouette_score(X, kmeans.labels_)\n",
    "# #     scores.append(score)\n",
    "\n",
    "# # plt.plot(range(2, 10), scores)\n",
    "# # plt.title('Elbow Method')\n",
    "# # plt.xlabel('Number of clusters')\n",
    "# # plt.ylabel('Silhouette Score')\n",
    "# # plt.show()\n",
    "\n",
    "# # from sklearn.metrics import silhouette_score\n",
    "\n",
    "# # best_n = 1\n",
    "# # best_score = -1\n",
    "\n",
    "# # for n_clusters in range(2, 10):\n",
    "# #     kmeans = KMeans(n_clusters=n_clusters)\n",
    "# #     kmeans.fit(X)\n",
    "# #     cluster_labels = kmeans.labels_\n",
    "# #     silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "# #     if silhouette_avg > best_score:\n",
    "# #         best_n = n_clusters\n",
    "# #         best_score = silhouette_avg\n",
    "\n",
    "# # print(\"Best number of clusters: \", best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "description of the solved problem – to be obvious that you understand the task\n",
    " input data description\n",
    " process steps, methods, techniques (e. g. description of data transformation)\n",
    " data exploration with proper charts/diagrams – to be obvious that you have\n",
    "understood data and relations\n",
    " (possibly simple) predictive or classification model (if not stated differently) for a\n",
    "proper target\n",
    " model performance evaluation\n",
    " summary, conclusion\n",
    "The expected volume of a report is 6 to 12 pages (recalculated to the A4 format) of text and\n",
    "charts\n",
    "\n",
    "Exploration tips:\n",
    " genres and interprets with most songs\n",
    " multigenre interprets\n",
    " distribution of songs features (word count, number of unique words etc.)\n",
    " song covers and remakes (same name and lyrics, possibly with small differences)\n",
    " typical words or patterns for various genres and for various interprets\n",
    "Model tips:\n",
    " classification of song to genre according to lyrics\n",
    " classification of song to interpret according to lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business understanding – What does the business need?\n",
    "Data understanding – What data do we have / need? Is it clean?\n",
    "Data preparation – How do we organize the data for modeling?\n",
    "\n",
    " Select data: Which (portions of) data sets will (not) be used and why?\n",
    " Collect additional data (internal, external)\n",
    " Clean data: The data is unlikely to be perfectly clean (error-free)\n",
    " Correct, replace, remove, ignore noise\n",
    " Track down sources to make specific data corrections\n",
    " Decide how to deal with special values and their meaning\n",
    " Aggregation level, missing values\n",
    " Outliers\n",
    " Construct data: Extract new attributes (or re-construct missing)\n",
    " E.g., body mass index\n",
    " Integrate data: Create new data sets by combining data from multiple sources\n",
    " Format data: Re-arrange, re-order, re-format\n",
    " E.g., convert string values that store numbers to numeric values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDB048 Data Science – Structure of Report\n",
    "1. Introduction\n",
    "● Reasons for carrying out analysis\n",
    "● What do we expect / what story are we telling?\n",
    "2. Data\n",
    "● Data size, format, fields, data types, …\n",
    "● Data source, reliability?\n",
    "● Basic statistics + visualizations\n",
    "● Sanity checks\n",
    "● Missing values, outliers, …\n",
    "3. Methodology\n",
    "● Description of data selection, cleaning, transformation\n",
    "● Discussion of the choice of analyses for the selected task\n",
    "● Description and assessment of the results\n",
    "● Description of usage of the approaches for Big Data processing (MapReduce\n",
    "/ Spark / multi-model DB) for a selected part of the analysis\n",
    "○ Note: Add the used source codes/scripts as an attachment\n",
    "● Possibly description of the iterations made\n",
    "4. Summary\n",
    "● Summarization of the findings\n",
    "● Possible exploitation, data/methodology extensions\n",
    "Typical problems:\n",
    "1. Useless graphs/tables (Does it carry any useful information? Why is it there?\n",
    "Is it worth it?)\n",
    "2. Too many similar graphs, inappropriate type of graphs\n",
    "3. No comments on the graphs/tables (What insights a graph provides should be\n",
    "summarised in text, too.)\n",
    "4. Graphs without appropriate description (axis labels, titles, population constraints, ...)\n",
    "5. Graph inconsistencies across a whole document (color, scales, graph types,\n",
    "…)\n",
    "6. No summary/conclusion\n",
    "7. Useless information (copying information from slides, list of used\n",
    "technologies, …)\n",
    "8. Reproducibility problems, code behind the report issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nápady:\n",
    "- popsat co dělám, co je mým cílem a jak to budu dělat\n",
    "- nejprve udělat nějaký základní profiling na datech\n",
    "- základní atributy jako jsme dělali v titanicu\n",
    "- kolik songů nemá lyrics nebo info o žánru...?\n",
    " genres and interprets with most songs\n",
    " multigenre interprets\n",
    " distribution of songs features (word count, number of unique words etc.)\n",
    " song covers and remakes (same name and lyrics, possibly with small differences)\n",
    " typical words or patterns for various genres and for various interprets\n",
    "- jaký interpret má nejvíc skladeb, jaký žánr?\n",
    "- zhodnotit kvalitu dat (konzistence sloupečků, chyby v textech? kódování? Nekde jsou uvozovky jinde ne, čárky v textu - styl různý, bude potřeba odstranit všechno tohle, lower)\n",
    "- udělat features ze slovíček\n",
    "- udělat nějaké statistiky ze slovíček\n",
    "- zobrazit nějaké korelace na grafu (z toho pak budou vycházet modely)\n",
    "- kouknout jestli nějak nesouvisí nějaký model co jsme dělali na Strojovém učení\n",
    "- ??? různé jazyky písniček - clustering?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
